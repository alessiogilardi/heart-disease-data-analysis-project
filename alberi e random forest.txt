1. Decision tree
    - eseguo split successivi scegliendo la feature su cui eseguire lo spelit in base alla sua importanza
    - basta una piccola defferenza sui dati per ottenere alberi molto diversi
    - posso visualizzare come sono arrivato ad una soluzione
    - non hanno bisogno di normalizzare i dati -> ???
    - non hanno bisogno di eliminare i valori nulli -> ???
    - dummy features -> ???
    
2. Random Forest Classifier
    - Uso un insieme di alberi indipendenti tra loro, alla fine viene fatta una votazione dai vari alberi in modo da determinare la risposta
    - Per ottenere alberi indipendenti:
        - Bagging (Bootstrap Aggregation)
        - Feature Randomness 

FARE ATTENZIONE: Cross validation: 
By performing an initial analysis to identify the most informative features using the entire data set
– if feature selection or model tuning is required by the modeling procedure, this must be repeated 
on every training set.
Otherwise, predictions will certainly be upwardly biased. If cross-validation is used to decide
which features to use, an inner cross-validation to carry out the feature selection on every training set must be performed.


Passi:
1. Data exploration
2. Data preparation and cleaning
3.0 Inner cross validation
3. Feature importance to reduce dimnesionality
4. Hyperparameters tuning (using also cross validation to have more precise accuracy)
    - Faccio tuning mostrando come varia l'accuratezza su train set e come varia su test set
    - Vedo quelle che mi danno il maggior incremento di accuratezza
5. Cross validation -> la cross validation viene fatta col train set solamente
6. Confusion matrix per valutare la bontà di un modello
